import streamlit as st
import requests
import json
import os
import re
import time
import uuid
import sqlite3
from datetime import datetime
import tiktoken
from typing import List, Dict, Any, Optional
import hashlib

# === Konfiguracja ===
KNOWLEDGE_CATEGORIES = [
    "Komponenty UI",
    "Integracja API",
    "Implementacja AI",
    "Przetwarzanie danych",
    "Optymalizacja wydajno≈õci",
    "Og√≥lne"
]

MODEL_OPTIONS = [
    {
        "id": "anthropic/claude-3.7-sonnet",
        "name": "Claude 3.7 Sonnet",
        "pricing": {"prompt": 3.0, "completion": 15.0},
        "description": "Zalecany - Najnowszy model Claude z doskona≈Çymi umiejƒôtno≈õciami kodowania"
    },
    {
        "id": "openai/gpt-4o",
        "name": "GPT-4o",
        "pricing": {"prompt": 2.5, "completion": 10.0},
        "description": "Silna alternatywa z dobrymi zdolno≈õciami kodowania"
    },
    {
        "id": "anthropic/claude-3.5-haiku",
        "name": "Claude 3.5 Haiku",
        "pricing": {"prompt": 0.8, "completion": 4.0},
        "description": "Szybszy, ta≈Ñszy model do prostszych zada≈Ñ"
    }
]

DEFAULT_SYSTEM_PROMPT = """Jeste≈õ ekspertkim asystentem specjalizujƒÖcym siƒô w tworzeniu aplikacji Streamlit wykorzystujƒÖcych AI. 
Pomagasz projektowaƒá, kodowaƒá i optymalizowaƒá aplikacje Streamlit, szczeg√≥lnie te korzystajƒÖce z modeli jƒôzykowych i innych us≈Çug AI.

Twoja wiedza specjalistyczna obejmuje:
1. Pisanie czystego, efektywnego kodu Streamlit
2. Projektowanie skutecznych interfejs√≥w u≈ºytkownika wykorzystujƒÖcych AI
3. Integracjƒô z API jak OpenRouter, OpenAI, Anthropic, itp.
4. Optymalizacjƒô wydajno≈õci i koszt√≥w przy korzystaniu z us≈Çug AI
5. Wdra≈ºanie najlepszych praktyk dla aplikacji Streamlit

Gdy podajesz przyk≈Çady kodu, przestrzegaj tych zasad:
- Do≈ÇƒÖczaj kompletne, dzia≈ÇajƒÖce rozwiƒÖzania, kt√≥re mo≈ºna skopiowaƒá i u≈ºyƒá bezpo≈õrednio
- Dodawaj kr√≥tkie komentarze wyja≈õniajƒÖce z≈Ço≈ºone czƒô≈õci
- Formatuj kod z odpowiednim wciƒôciem i strukturƒÖ
- Skup siƒô na najlepszych praktykach i efektywnych wzorcach Streamlit

Zawsze dziel aplikacje na logiczne komponenty i funkcje, zamiast pisaƒá wszystko w jednym bloku kodu.
Pamiƒôtaj o zarzƒÖdzaniu stanem sesji w Streamlit i optymalizacji koszt√≥w przy korzystaniu z API modeli jƒôzykowych.
"""

# === ZarzƒÖdzanie bazƒÖ danych ===
class AssistantDB:
    def __init__(self, db_path='streamlit_assistant.db'):
        """Inicjalizacja po≈ÇƒÖczenia z bazƒÖ danych i tabel"""
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self._create_tables()
    
    def _create_tables(self):
        """Utw√≥rz tabele bazy danych, je≈õli nie istniejƒÖ"""
        cursor = self.conn.cursor()
        
        # Tabela konwersacji
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS conversations (
            id TEXT PRIMARY KEY,
            title TEXT,
            created_at TIMESTAMP,
            updated_at TIMESTAMP
        )
        ''')
        
        # Tabela wiadomo≈õci
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            id TEXT PRIMARY KEY,
            conversation_id TEXT,
            role TEXT,
            content TEXT,
            timestamp TIMESTAMP,
            FOREIGN KEY (conversation_id) REFERENCES conversations (id)
        )
        ''')
        
        # Tabela bazy wiedzy
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS knowledge_items (
            id TEXT PRIMARY KEY,
            title TEXT,
            content TEXT,
            category TEXT,
            tags TEXT,
            created_at TIMESTAMP
        )
        ''')
        
        self.conn.commit()

    def save_message(self, conversation_id: str, role: str, content: str) -> str:
        """Zapisz wiadomo≈õƒá w bazie danych"""
        cursor = self.conn.cursor()
        message_id = str(uuid.uuid4())
        cursor.execute(
            "INSERT INTO messages (id, conversation_id, role, content, timestamp) VALUES (?, ?, ?, ?, ?)",
            (message_id, conversation_id, role, content, datetime.now())
        )
        self.conn.commit()
        return message_id
    
    def get_messages(self, conversation_id: str) -> List[Dict[str, Any]]:
        """Pobierz wszystkie wiadomo≈õci dla konwersacji"""
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT role, content FROM messages WHERE conversation_id = ? ORDER BY timestamp",
            (conversation_id,)
        )
        return [{"role": role, "content": content} for role, content in cursor.fetchall()]

    def save_conversation(self, conversation_id: str, title: str):
        """Utw√≥rz lub zaktualizuj konwersacjƒô"""
        cursor = self.conn.cursor()
        now = datetime.now()
        
        # Sprawd≈∫, czy konwersacja istnieje
        cursor.execute("SELECT id FROM conversations WHERE id = ?", (conversation_id,))
        if cursor.fetchone():
            # Aktualizuj istniejƒÖcƒÖ konwersacjƒô
            cursor.execute(
                "UPDATE conversations SET title = ?, updated_at = ? WHERE id = ?",
                (title, now, conversation_id)
            )
        else:
            # Utw√≥rz nowƒÖ konwersacjƒô
            cursor.execute(
                "INSERT INTO conversations (id, title, created_at, updated_at) VALUES (?, ?, ?, ?)",
                (conversation_id, title, now, now)
            )
        
        self.conn.commit()
    
    def get_conversations(self) -> List[Dict[str, Any]]:
        """Pobierz wszystkie konwersacje"""
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT id, title, created_at FROM conversations ORDER BY updated_at DESC"
        )
        return [
            {"id": conv_id, "title": title, "created_at": created_at} 
            for conv_id, title, created_at in cursor.fetchall()
        ]

    def delete_conversation(self, conversation_id: str):
        """Usu≈Ñ konwersacjƒô i jej wiadomo≈õci"""
        cursor = self.conn.cursor()
        # Najpierw usu≈Ñ wiadomo≈õci (ograniczenie klucza obcego)
        cursor.execute("DELETE FROM messages WHERE conversation_id = ?", (conversation_id,))
        # Usu≈Ñ konwersacjƒô
        cursor.execute("DELETE FROM conversations WHERE id = ?", (conversation_id,))
        self.conn.commit()

    def save_knowledge_item(self, title: str, content: str, category: str, tags: List[str] = None) -> str:
        """Zapisz element w bazie wiedzy"""
        cursor = self.conn.cursor()
        item_id = str(uuid.uuid4())
        tags_json = json.dumps(tags or [])
        
        cursor.execute(
            "INSERT INTO knowledge_items (id, title, content, category, tags, created_at) VALUES (?, ?, ?, ?, ?, ?)",
            (item_id, title, content, category, tags_json, datetime.now())
        )
        
        self.conn.commit()
        return item_id

    def get_knowledge_items(self, category: str = None) -> List[Dict[str, Any]]:
        """Pobierz wszystkie elementy bazy wiedzy, opcjonalnie filtrowane wed≈Çug kategorii"""
        cursor = self.conn.cursor()
        
        if category and category != "Wszystkie":
            cursor.execute(
                "SELECT id, title, content, category, tags FROM knowledge_items WHERE category = ? ORDER BY created_at DESC",
                (category,)
            )
        else:
            cursor.execute(
                "SELECT id, title, content, category, tags FROM knowledge_items ORDER BY created_at DESC"
            )
        
        return [
            {
                "id": item_id,
                "title": title,
                "content": content,
                "category": category,
                "tags": json.loads(tags)
            }
            for item_id, title, content, category, tags in cursor.fetchall()
        ]

    def search_knowledge_base(self, query: str, category: str = None) -> List[Dict[str, Any]]:
        """Przeszukaj bazƒô wiedzy wed≈Çug tekstu zapytania"""
        cursor = self.conn.cursor()
        search_term = f"%{query}%"
        
        if category and category != "Wszystkie":
            cursor.execute(
                "SELECT id, title, content, category, tags FROM knowledge_items WHERE (title LIKE ? OR content LIKE ?) AND category = ? ORDER BY created_at DESC",
                (search_term, search_term, category)
            )
        else:
            cursor.execute(
                "SELECT id, title, content, category, tags FROM knowledge_items WHERE title LIKE ? OR content LIKE ? ORDER BY created_at DESC",
                (search_term, search_term)
            )
        
        return [
            {
                "id": item_id,
                "title": title,
                "content": content,
                "category": category,
                "tags": json.loads(tags)
            }
            for item_id, title, content, category, tags in cursor.fetchall()
        ]

    def delete_knowledge_item(self, item_id: str):
        """Usu≈Ñ element bazy wiedzy"""
        cursor = self.conn.cursor()
        cursor.execute("DELETE FROM knowledge_items WHERE id = ?", (item_id,))
        self.conn.commit()

    def update_knowledge_item(self, item_id: str, title: str, content: str, category: str, tags: List[str] = None):
        """Aktualizuj element bazy wiedzy"""
        cursor = self.conn.cursor()
        tags_json = json.dumps(tags or [])
        
        cursor.execute(
            "UPDATE knowledge_items SET title = ?, content = ?, category = ?, tags = ? WHERE id = ?",
            (title, content, category, tags_json, item_id)
        )
        
        self.conn.commit()

# === Serwis LLM ===
class LLMService:
    def __init__(self, api_key: str):
        self.api_key = api_key
        
        # Prosta pamiƒôƒá podrƒôczna dla powtarzajƒÖcych siƒô pyta≈Ñ
        self.cache = {}

    def count_tokens(self, text: str) -> int:
        """Oszacuj liczbƒô token√≥w dla Claude"""
        try:
            encoding = tiktoken.encoding_for_model("gpt-4")  # U≈ºywamy kodowania gpt-4 jako przybli≈ºenia
            return len(encoding.encode(text))
        except:
            # Fallback do cl100k_base, je≈õli okre≈õlone kodowanie nie jest dostƒôpne
            encoding = tiktoken.get_encoding("cl100k_base")
            return len(encoding.encode(text))

    def get_cache_key(self, messages, model, system_prompt, temperature):
        """Generuj klucz pamiƒôci podrƒôcznej dla zapytania LLM"""
        cache_input = f"{json.dumps(messages)}-{model}-{system_prompt}-{temperature}"
        return hashlib.md5(cache_input.encode()).hexdigest()

    def call_llm(self, 
                messages: List[Dict[str, str]], 
                model: str = "anthropic/claude-3.7-sonnet", 
                system_prompt: str = None, 
                temperature: float = 0.7, 
                max_tokens: int = 4000,
                use_cache: bool = True) -> Dict[str, Any]:
        """Wywo≈Çaj API LLM przez OpenRouter z opcjonalnym cachowaniem"""
        # Sprawd≈∫ pamiƒôƒá podrƒôcznƒÖ, je≈õli u≈ºywamy cachowania
        if use_cache and temperature < 0.1:  # Cachujemy tylko deterministyczne odpowiedzi
            cache_key = self.get_cache_key(messages, model, system_prompt, temperature)
            if cache_key in self.cache:
                return self.cache[cache_key]
        
        # Przygotuj wiadomo≈õci z promptem systemowym, je≈õli podano
        api_messages = []
        if system_prompt:
            api_messages.append({"role": "system", "content": system_prompt})
        api_messages.extend(messages)
        
        # Oblicz tokeny promptu
        prompt_text = system_prompt or ""
        for msg in messages:
            prompt_text += msg["content"]
        prompt_tokens = self.count_tokens(prompt_text)
        
        # Zdefiniuj parametry ponawiania
        max_retries = 3
        retry_delay = 2  # sekundy
        
        # Pr√≥ba wywo≈Çania API z ponawianiem
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": model,
                        "messages": api_messages,
                        "temperature": temperature,
                        "max_tokens": max_tokens
                    },
                    timeout=30
                )
                response.raise_for_status()
                result = response.json()
                
                # Oszacuj tokeny odpowiedzi
                response_content = result["choices"][0]["message"]["content"]
                completion_tokens = self.count_tokens(response_content)
                
                # Dodaj informacje o tokenach i tworzenach do wyniku
                result["usage"] = {
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": prompt_tokens + completion_tokens
                }
                
                # Dodaj do pamiƒôci podrƒôcznej, je≈õli u≈ºywamy cachowania
                if use_cache and temperature < 0.1:
                    cache_key = self.get_cache_key(messages, model, system_prompt, temperature)
                    self.cache[cache_key] = result
                
                return result
            
            except requests.exceptions.RequestException as e:
                if attempt == max_retries - 1:  # Ostatnia pr√≥ba
                    raise Exception(f"Nie uda≈Ço siƒô po≈ÇƒÖczyƒá z API po {max_retries} pr√≥bach: {str(e)}")
                
                # Czekaj przed ponowieniem
                time.sleep(retry_delay * (2 ** attempt))  # Wyk≈Çadnicze wycofanie

# === Funkcje pomocnicze ===
def calculate_cost(model_id: str, prompt_tokens: int, completion_tokens: int) -> float:
    """Oblicz szacowany koszt zapytania w USD"""
    for model in MODEL_OPTIONS:
        if model["id"] == model_id:
            return (prompt_tokens / 1_000_000) * model["pricing"]["prompt"] + \
                   (completion_tokens / 1_000_000) * model["pricing"]["completion"]
    return 0.0  # W przypadku nieznalezienia modelu

def format_message_for_display(message: Dict[str, str]) -> str:
    """Formatuj wiadomo≈õƒá do wy≈õwietlenia w interfejsie, ze wsparciem dla blok√≥w kodu"""
    content = message.get("content", "")
    
    # Wyodrƒôbnianie i formatowanie blok√≥w kodu
    def replace_code_block(match):
        lang = match.group(1) or ""
        code = match.group(2)
        return f"```{lang}\n{code}\n```"
    
    # ZastƒÖp bloki kodu ze sk≈ÇadniƒÖ markdown
    content = re.sub(r"```(.*?)\n(.*?)```", replace_code_block, content, flags=re.DOTALL)
    
    return content

def get_conversation_title(messages: List[Dict[str, str]], llm_service: LLMService, api_key: str) -> str:
    """Wygeneruj tytu≈Ç dla nowej konwersacji na podstawie pierwszej wiadomo≈õci u≈ºytkownika"""
    if not messages:
        return f"Nowa konwersacja {datetime.now().strftime('%d-%m-%Y %H:%M')}"
    
    # U≈ºyj pierwszej wiadomo≈õci u≈ºytkownika jako podstawy tytu≈Çu
    user_message = next((m["content"] for m in messages if m["role"] == "user"), "")
    
    if len(user_message) > 40:
        # Skorzystaj z LLM, aby stworzyƒá kr√≥tki, opisowy tytu≈Ç
        try:
            response = llm_service.call_llm(
                messages=[
                    {"role": "user", "content": f"Utw√≥rz kr√≥tki, opisowy tytu≈Ç (max. 5 s≈Ç√≥w) dla nastƒôpujƒÖcej konwersacji, bez cudzys≈Çow√≥w: {user_message[:200]}..."}
                ],
                model="anthropic/claude-3.5-haiku",  # Ta≈Ñszy model jest wystarczajƒÖcy do tworzenia tytu≈Ç√≥w
                system_prompt="Jeste≈õ pomocnym asystentem, kt√≥ry tworzy kr√≥tkie, opisowe tytu≈Çy konwersacji.",
                temperature=0.2,
                max_tokens=20,
                use_cache=True
            )
            title = response["choices"][0]["message"]["content"].strip().strip('"\'')
            # Usu≈Ñ znaki, kt√≥re mog≈Çyby sprawiaƒá problemy z interfejsem
            title = re.sub(r'[^\w\s\-.,]', '', title)
            return title[:40]
        except Exception:
            # W przypadku b≈Çƒôdu, wr√≥ƒá do domy≈õlnego tytu≈Çu
            pass
    
    # Domy≈õlnie u≈ºyj skr√≥conej wiadomo≈õci u≈ºytkownika
    return user_message[:40] + ("..." if len(user_message) > 40 else "")

# === Komponenty interfejsu u≈ºytkownika ===
def sidebar_component():
    """Komponent paska bocznego z konwersacjami i ustawieniami"""
    st.sidebar.title("AI Asystent Developera")
    
    # Opcje nawigacji
    page = st.sidebar.radio("Nawigacja", ["Chat Asystent", "Baza Wiedzy"])
    
    # Ustawienia API
    with st.sidebar.expander("üîë Ustawienia API", expanded=False):
        api_key = st.text_input(
            "Klucz API OpenRouter",
            value=st.session_state.get("api_key", ""),
            type="password",
            help="Wprowad≈∫ sw√≥j klucz API OpenRouter"
        )
        
        if api_key:
            st.session_state["api_key"] = api_key
    
    # Ustawienia modelu w sekcji Chat
    if page == "Chat Asystent":
        with st.sidebar.expander("‚öôÔ∏è Ustawienia modelu", expanded=False):
            model_options = {model["id"]: f"{model['name']}" for model in MODEL_OPTIONS}
            selected_model = st.selectbox(
                "Model LLM",
                options=list(model_options.keys()),
                format_func=lambda x: model_options[x],
                index=0,
                key="model_selection"
            )
            
            # Poka≈º opis modelu
            for model in MODEL_OPTIONS:
                if model["id"] == selected_model:
                    st.info(model["description"])
            
            temperature = st.slider(
                "Temperatura",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.get("temperature", 0.7),
                step=0.1,
                help="Wy≈ºsza warto≈õƒá = bardziej kreatywne odpowiedzi"
            )
            
            st.session_state["temperature"] = temperature
            
            custom_system_prompt = st.text_area(
                "Prompt systemowy (opcjonalnie)",
                value=st.session_state.get("custom_system_prompt", DEFAULT_SYSTEM_PROMPT),
                help="Dostosuj zachowanie asystenta"
            )
            
            if st.button("Zresetuj do domy≈õlnego"):
                custom_system_prompt = DEFAULT_SYSTEM_PROMPT
            
            st.session_state["custom_system_prompt"] = custom_system_prompt
        
        # Lista konwersacji
        db = st.session_state.get("db")
        if db:
            with st.sidebar.expander("üí¨ Konwersacje", expanded=True):
                conversations = db.get_conversations()
                
                if conversations:
                    for conv in conversations:
                        col1, col2 = st.columns([4, 1])
                        with col1:
                            if st.button(conv["title"], key=f"conv_{conv['id']}", use_container_width=True):
                                st.session_state["current_conversation_id"] = conv["id"]
                                st.rerun()
                        with col2:
                            if st.button("üóëÔ∏è", key=f"del_{conv['id']}", help="Usu≈Ñ konwersacjƒô"):
                                db.delete_conversation(conv["id"])
                                if st.session_state.get("current_conversation_id") == conv["id"]:
                                    st.session_state["current_conversation_id"] = None
                                st.rerun()
                else:
                    st.write("Brak zapisanych konwersacji")
            
            # Przycisk nowej konwersacji
            if st.sidebar.button("‚ûï Nowa konwersacja", use_container_width=True):
                st.session_state["current_conversation_id"] = str(uuid.uuid4())
                st.rerun()
    
    return page

def chat_component():
    """Komponent interfejsu czatu"""
    st.title("üí¨ Chat Asystent Developera Streamlit")
    
    # Sprawd≈∫, czy klucz API jest ustawiony
    if not st.session_state.get("api_key"):
        st.warning("‚ö†Ô∏è Wprowad≈∫ sw√≥j klucz API OpenRouter w ustawieniach, aby korzystaƒá z asystenta.")
        return
    
    # Pobierz instancjƒô serwisu LLM i bazy danych
    llm_service = st.session_state.get("llm_service")
    db = st.session_state.get("db")
    
    if not llm_service or not db:
        st.error("‚ö†Ô∏è Nie mo≈ºna zainicjalizowaƒá serwis√≥w. Od≈õwie≈º stronƒô i spr√≥buj ponownie.")
        return
    
    # Inicjalizacja zmiennych sesji dla konwersacji
    if "current_conversation_id" not in st.session_state:
        st.session_state["current_conversation_id"] = str(uuid.uuid4())
    
    current_conversation_id = st.session_state["current_conversation_id"]
    
    # Statystyki konwersacji
    if "token_usage" not in st.session_state:
        st.session_state["token_usage"] = {"prompt": 0, "completion": 0, "cost": 0.0}
    
    with st.expander("üìä Statystyki token√≥w", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Tokeny prompt", st.session_state["token_usage"]["prompt"])
        with col2:
            st.metric("Tokeny completion", st.session_state["token_usage"]["completion"])
        with col3:
            st.metric("Szacunkowy koszt", f"${st.session_state['token_usage']['cost']:.4f}")
    
    # Wy≈õwietl istniejƒÖce wiadomo≈õci
    messages = db.get_messages(current_conversation_id)
    
    if not messages:
        # Komunikat powitalny dla nowej konwersacji
        st.markdown(""" 
        ### üëã Witaj w Asystencie Developera Streamlit!
        
        Jestem tu, aby pom√≥c Ci projektowaƒá i tworzyƒá aplikacje Streamlit z wykorzystaniem AI. 
        Mo≈ºesz zadaƒá mi pytania dotyczƒÖce:
        
        - Projektowania interfejsu u≈ºytkownika w Streamlit
        - Implementacji funkcjonalno≈õci AI w aplikacjach
        - Integracji z APIami (OpenRouter, OpenAI, Anthropic, itp.)
        - Optymalizacji wydajno≈õci i koszt√≥w
        - Przyk≈Çad√≥w kodu i komponent√≥w
        
        Zacznij od opisania aplikacji, kt√≥rƒÖ chcesz stworzyƒá lub zapytaj o konkretne rozwiƒÖzanie.
        """)
    else:
        for message in messages:
            role = message["role"]
            content = format_message_for_display(message)
            
            if role == "user":
                st.chat_message("user").markdown(content)
            elif role == "assistant":
                with st.chat_message("assistant"):
                    st.markdown(content)
    
    # Input u≈ºytkownika
    prompt = st.chat_input("Wpisz swoje pytanie lub zadanie...")
    
    if prompt:
        # Sprawd≈∫, czy konwersacja ma tytu≈Ç
        if len(messages) == 0:
            conversation_title = get_conversation_title([{"role": "user", "content": prompt}], llm_service, st.session_state["api_key"])
            db.save_conversation(current_conversation_id, conversation_title)
        
        # Wy≈õwietl wiadomo≈õƒá u≈ºytkownika
        st.chat_message("user").markdown(prompt)
        
        # Zapisz wiadomo≈õƒá u≈ºytkownika
        db.save_message(current_conversation_id, "user", prompt)
        
        # Przygotuj wiadomo≈õci dla API
        api_messages = db.get_messages(current_conversation_id)
        
        # Uzyskaj odpowied≈∫ asystenta
        with st.spinner("Generowanie odpowiedzi..."):
            try:
                model = st.session_state.get("model_selection", MODEL_OPTIONS[0]["id"])
                system_prompt = st.session_state.get("custom_system_prompt", DEFAULT_SYSTEM_PROMPT)
                temperature = st.session_state.get("temperature", 0.7)
                
                response = llm_service.call_llm(
                    messages=api_messages,
                    model=model,
                    system_prompt=system_prompt,
                    temperature=temperature
                )
                
                assistant_response = response["choices"][0]["message"]["content"]
                
                # Aktualizuj statystyki token√≥w
                if "usage" in response:
                    usage = response["usage"]
                    st.session_state["token_usage"]["prompt"] += usage["prompt_tokens"]
                    st.session_state["token_usage"]["completion"] += usage["completion_tokens"]
                    
                    # Oblicz koszt
                    cost = calculate_cost(
                        model, 
                        usage["prompt_tokens"], 
                        usage["completion_tokens"]
                    )
                    
                    st.session_state["token_usage"]["cost"] += cost
                
                # Wy≈õwietl odpowied≈∫ asystenta
                with st.chat_message("assistant"):
                    st.markdown(assistant_response)
                
                # Zapisz odpowied≈∫ asystenta
                db.save_message(current_conversation_id, "assistant", assistant_response)
                
            except Exception as e:
                st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd: {str(e)}")
def knowledge_base_component():
    """Komponent bazy wiedzy"""
    st.title("üìö Baza Wiedzy")
    
    db = st.session_state.get("db")
    if not db:
        st.error("‚ö†Ô∏è Nie mo≈ºna zainicjalizowaƒá bazy danych. Od≈õwie≈º stronƒô i spr√≥buj ponownie.")
        return
    
    tab1, tab2 = st.tabs(["PrzeglƒÖdaj", "Dodaj nowy"])
    
    with tab1:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            search_query = st.text_input("üîç Szukaj w bazie wiedzy", placeholder="Wpisz zapytanie...")
        
        with col2:
            categories = ["Wszystkie"] + KNOWLEDGE_CATEGORIES
            selected_category = st.selectbox("Kategoria", categories)
        
        # Pobierz i wy≈õwietl elementy bazy wiedzy
        if search_query:
            items = db.search_knowledge_base(search_query, selected_category if selected_category != "Wszystkie" else None)
        else:
            items = db.get_knowledge_items(selected_category if selected_category != "Wszystkie" else None)
        
        if not items:
            st.info("Nie znaleziono pasujƒÖcych element√≥w bazy wiedzy.")
        else:
            for item in items:
                with st.expander(f"**{item['title']}** ({item['category']})"):
                    st.markdown(item["content"])
                    
                    col1, col2 = st.columns([1, 6])
                    with col1:
                        if st.button("Usu≈Ñ", key=f"del_kb_{item['id']}", help="Usu≈Ñ ten element z bazy wiedzy"):
                            db.delete_knowledge_item(item["id"])
                            st.success("Element usuniƒôty!")
                            st.rerun()
                    
                    with col2:
                        if st.button("Edytuj", key=f"edit_kb_{item['id']}", help="Edytuj ten element"):
                            st.session_state["editing_item"] = item
                            st.rerun()
    
    with tab2:
        # Edycja istniejƒÖcego elementu
        editing_item = st.session_state.get("editing_item")
        
        if editing_item:
            st.subheader("Edytuj element bazy wiedzy")
            item_title = st.text_input("Tytu≈Ç", value=editing_item["title"])
            item_category = st.selectbox("Kategoria", KNOWLEDGE_CATEGORIES, index=KNOWLEDGE_CATEGORIES.index(editing_item["category"]) if editing_item["category"] in KNOWLEDGE_CATEGORIES else 0)
            item_content = st.text_area("Zawarto≈õƒá (wspierane Markdown)", value=editing_item["content"], height=300)
            item_tags = st.multiselect("Tagi (opcjonalnie)", options=["Kod", "Komponent", "Integracja", "Design"], default=editing_item["tags"])
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Anuluj edycjƒô"):
                    st.session_state.pop("editing_item", None)
                    st.rerun()
            
            with col2:
                if st.button("Zapisz zmiany"):
                    db.update_knowledge_item(
                        editing_item["id"],
                        item_title,
                        item_content,
                        item_category,
                        item_tags
                    )
                    st.success("Element zaktualizowany!")
                    st.session_state.pop("editing_item", None)
                    st.rerun()
        
        # Dodawanie nowego elementu
        else:
            st.subheader("Dodaj nowy element do bazy wiedzy")
            item_title = st.text_input("Tytu≈Ç", placeholder="Np. Komponent wyboru plik√≥w z podglƒÖdem")
            item_category = st.selectbox("Kategoria", KNOWLEDGE_CATEGORIES)
            item_content = st.text_area("Zawarto≈õƒá (wspierane Markdown)", placeholder="Wpisz zawarto≈õƒá, kod, fragmenty...", height=300)
            item_tags = st.multiselect("Tagi (opcjonalnie)", options=["Kod", "Komponent", "Integracja", "Design"])
            
            if st.button("Dodaj do bazy wiedzy"):
                if item_title and item_content:
                    db.save_knowledge_item(
                        item_title,
                        item_content,
                        item_category,
                        item_tags
                    )
                    st.success("Dodano do bazy wiedzy!")
                    # Wyczy≈õƒá pola po dodaniu
                    st.session_state["new_item_title"] = ""
                    st.session_state["new_item_content"] = ""
                    st.rerun()
                else:
                    st.error("Tytu≈Ç i zawarto≈õƒá sƒÖ wymagane.")
# === Komponent wyszukiwania i generowania komponent√≥w ===
def component_generator():
    """Komponent do wyszukiwania i generowania komponent√≥w Streamlit"""
    st.subheader("üîç Generator Komponent√≥w")
    
    # Sprawd≈∫ inicjalizacjƒô serwis√≥w
    llm_service = st.session_state.get("llm_service")
    db = st.session_state.get("db")
    
    if not llm_service or not db:
        st.error("‚ö†Ô∏è Nie mo≈ºna zainicjalizowaƒá serwis√≥w. Od≈õwie≈º stronƒô i spr√≥buj ponownie.")
        return
    
    # Interface
    component_query = st.text_input(
        "Opisz komponent, kt√≥ry chcesz wygenerowaƒá",
        placeholder="Np. Interaktywny selektor plik√≥w z podglƒÖdem obraz√≥w"
    )
    
    # Opcje zaawansowane
    with st.expander("Opcje zaawansowane", expanded=False):
        include_comments = st.checkbox("Dodaj komentarze w kodzie", value=True)
        use_examples = st.checkbox("Dodaj przyk≈Çad u≈ºycia", value=True)
        optimization_level = st.slider(
            "Poziom optymalizacji",
            min_value=1,
            max_value=3,
            value=2,
            help="1: Podstawowy kod, 2: Zoptymalizowany, 3: Zaawansowana optymalizacja"
        )
    
    # Przycisk generowania
    if st.button("Generuj komponent") and component_query:
        with st.spinner("Generowanie komponentu..."):
            try:
                # Przygotuj zapytanie
                prompt = f"""
                Wygeneruj komponent Streamlit wed≈Çug nastƒôpujƒÖcego opisu:
                
                {component_query}
                
                {"Dodaj komentarze wyja≈õniajƒÖce kod." if include_comments else ""}
                {"Dodaj przyk≈Çad u≈ºycia w praktyce." if use_examples else ""}
                Poziom optymalizacji: {'Podstawowy' if optimization_level == 1 else 'Optymalny' if optimization_level == 2 else 'Zaawansowany'}
                
                Zwr√≥ƒá kompletny, gotowy do u≈ºycia fragment kodu, kt√≥ry mo≈ºna bezpo≈õrednio wkleiƒá do aplikacji Streamlit.
                """
                
                # Wybierz model w zale≈ºno≈õci od z≈Ço≈ºono≈õci zapytania
                model = "anthropic/claude-3.7-sonnet"  # Domy≈õlnie u≈ºywamy najsilniejszego modelu dla kompleksowego kodu
                
                response = llm_service.call_llm(
                    messages=[{"role": "user", "content": prompt}],
                    model=model,
                    system_prompt=DEFAULT_SYSTEM_PROMPT,
                    temperature=0.2  # Ni≈ºsza temperatura dla bardziej deterministycznego kodu
                )
                
                # Obs≈Çuga i wy≈õwietlanie wynik√≥w
                result = response["choices"][0]["message"]["content"]
                
                # Aktualizuj statystyki token√≥w
                if "usage" in response:
                    usage = response["usage"]
                    st.session_state["token_usage"]["prompt"] += usage["prompt_tokens"]
                    st.session_state["token_usage"]["completion"] += usage["completion_tokens"]
                    cost = calculate_cost(model, usage["prompt_tokens"], usage["completion_tokens"])
                    st.session_state["token_usage"]["cost"] += cost
                
                # Wyodrƒôbnij kod z odpowiedzi (je≈õli jest w bloku kodu)
                code_pattern = r"```(?:python)?\n(.*?)```"
                code_match = re.search(code_pattern, result, re.DOTALL)
                
                if code_match:
                    generated_code = code_match.group(1)
                else:
                    generated_code = result
                
                # Wy≈õwietl wynik
                st.success("‚úÖ Komponent wygenerowany!")
                
                st.code(generated_code, language="python")
                
                # Przycisk kopiowania
                st.button(
                    "üìã Kopiuj kod do schowka", 
                    on_click=lambda: st.write("Kod skopiowany do schowka!")
                )
                
                # Opcja zapisania do bazy wiedzy
                st.write("---")
                save_title = st.text_input("Tytu≈Ç dla bazy wiedzy", value=component_query[:50])
                
                if st.button("üíæ Zapisz do bazy wiedzy"):
                    if save_title:
                        db.save_knowledge_item(
                            save_title,
                            f"### {save_title}\n\n```python\n{generated_code}\n```",
                            "Komponenty UI",
                            ["Kod", "Komponent", "Wygenerowany"]
                        )
                        st.success("‚úÖ Zapisano w bazie wiedzy!")
                    else:
                        st.error("Podaj tytu≈Ç, aby zapisaƒá komponent.")
                
            except Exception as e:
                st.error(f"WystƒÖpi≈Ç b≈ÇƒÖd podczas generowania komponentu: {str(e)}")
# === G≈Ç√≥wna aplikacja ===
def main():
    st.set_page_config(
        page_title="AI Asystent Developera Streamlit",
        page_icon="ü§ñ",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Inicjalizacja serwis√≥w
    if "db" not in st.session_state:
        st.session_state["db"] = AssistantDB()
    
    if "api_key" in st.session_state and "llm_service" not in st.session_state:
        st.session_state["llm_service"] = LLMService(st.session_state["api_key"])
    
    # Wy≈õwietl sidebar
    page = sidebar_component()
    
    # Wy≈õwietl g≈Ç√≥wny komponent
    if page == "Chat Asystent":
        # Podziel na zak≈Çadki dla g≈Ç√≥wnego chata i generatora komponent√≥w
        chat_tab, generator_tab = st.tabs(["üí¨ Chat", "üß© Generator Komponent√≥w"])
        
        with chat_tab:
            chat_component()
        
        with generator_tab:
            component_generator()
    
    elif page == "Baza Wiedzy":
        knowledge_base_component()

if __name__ == "__main__":
    main()