import streamlit as st
import requests
import json
import os
import re
import time
import uuid
import sqlite3
from datetime import datetime
import tiktoken
from typing import List, Dict, Any, Optional
import hashlib
from functools import wraps
import base64
import io
import traceback

# === Konfiguracja ===
MODEL_OPTIONS = [
    {
        "id": "anthropic/claude-3.7-sonnet:floor",
        "name": "Claude 3.7 Sonnet",
        "pricing": {"prompt": 3.0, "completion": 15.0},
        "description": "Zalecany - Najnowszy model Claude z doskonaÅ‚ymi umiejÄ™tnoÅ›ciami kodowania"
    },
    {
        "id": "anthropic/claude-3.7-sonnet:thinking",
        "name": "Claude 3.7 Sonnet Thinking",
        "pricing": {"prompt": 3.0, "completion": 15.0},
        "description": "Model Claude wykorzystujÄ…cy dodatkowy czas na analizÄ™ problemÃ³w"
    },
    {
        "id": "openai/gpt-4o:floor",
        "name": "GPT-4o",
        "pricing": {"prompt": 2.5, "completion": 10.0},
        "description": "Silna alternatywa z dobrymi zdolnoÅ›ciami kodowania i analizy obrazÃ³w"
    },
    {
        "id": "openai/gpt-4-turbo:floor",
        "name": "GPT-4 Turbo",
        "pricing": {"prompt": 2.5, "completion": 10.0},
        "description": "Nieco starszy model GPT-4 Turbo"
    },
    {
        "id": "anthropic/claude-3.5-haiku:floor",
        "name": "Claude 3.5 Haiku",
        "pricing": {"prompt": 0.8, "completion": 4.0},
        "description": "Szybszy, taÅ„szy model do prostszych zadaÅ„"
    }
]

DEFAULT_SYSTEM_PROMPT = """JesteÅ› ekspertkim asystentem specjalizujÄ…cym siÄ™ w tworzeniu aplikacji Streamlit wykorzystujÄ…cych AI. 
Pomagasz projektowaÄ‡, kodowaÄ‡ i optymalizowaÄ‡ aplikacje Streamlit, szczegÃ³lnie te korzystajÄ…ce z modeli jÄ™zykowych i innych usÅ‚ug AI.

Twoja wiedza specjalistyczna obejmuje:
1. Pisanie czystego, efektywnego kodu Streamlit
2. Projektowanie skutecznych interfejsÃ³w uÅ¼ytkownika wykorzystujÄ…cych AI
3. IntegracjÄ™ z API jak OpenRouter, OpenAI, Anthropic, itp.
4. OptymalizacjÄ™ wydajnoÅ›ci i kosztÃ³w przy korzystaniu z usÅ‚ug AI
5. WdraÅ¼anie najlepszych praktyk dla aplikacji Streamlit

Gdy podajesz przykÅ‚ady kodu, przestrzegaj tych zasad:
- DoÅ‚Ä…czaj kompletne, dziaÅ‚ajÄ…ce rozwiÄ…zania, ktÃ³re moÅ¼na skopiowaÄ‡ i uÅ¼yÄ‡ bezpoÅ›rednio
- Dodawaj krÃ³tkie komentarze wyjaÅ›niajÄ…ce zÅ‚oÅ¼one czÄ™Å›ci
- Formatuj kod z odpowiednim wciÄ™ciem i strukturÄ…
- Skup siÄ™ na najlepszych praktykach i efektywnych wzorcach Streamlit

Zawsze dziel aplikacje na logiczne komponenty i funkcje, zamiast pisaÄ‡ wszystko w jednym bloku kodu.
PamiÄ™taj o zarzÄ…dzaniu stanem sesji w Streamlit i optymalizacji kosztÃ³w przy korzystaniu z API modeli jÄ™zykowych.
"""

# === Funkcja dekoratora dla autoryzacji ===
def requires_auth(f):
    @wraps(f)
    def decorated(*args, **kwargs):
        if not st.session_state.get("authenticated", False):
            return login_page()
        return f(*args, **kwargs)
    return decorated

def login_page():
    """Strona logowania"""
    st.title("ğŸ”’ Logowanie")
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col2:
        st.markdown("### Zaloguj siÄ™, aby uzyskaÄ‡ dostÄ™p")
        
        username = st.text_input("Nazwa uÅ¼ytkownika", key="login_username")
        password = st.text_input("HasÅ‚o", type="password", key="login_password")
        
        if st.button("Zaloguj"):
            # Pobierz ustawienia z secrets
            correct_username = st.secrets.get("APP_USER", "admin")
            correct_password = st.secrets.get("APP_PASSWORD", "password")
            
            if username == correct_username and password == correct_password:
                st.session_state["authenticated"] = True
                st.success("Zalogowano pomyÅ›lnie!")
                st.rerun()
            else:
                st.error("NieprawidÅ‚owa nazwa uÅ¼ytkownika lub hasÅ‚o!")

# === ZarzÄ…dzanie bazÄ… danych ===
class AssistantDB:
    def __init__(self, db_path='streamlit_assistant.db'):
        """Inicjalizacja poÅ‚Ä…czenia z bazÄ… danych i tabel"""
        self.conn = sqlite3.connect(db_path, check_same_thread=False)
        self._create_tables()
    
    def _create_tables(self):
        """UtwÃ³rz tabele bazy danych, jeÅ›li nie istniejÄ…"""
        cursor = self.conn.cursor()
        
        # Tabela konwersacji
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS conversations (
            id TEXT PRIMARY KEY,
            title TEXT,
            created_at TIMESTAMP,
            updated_at TIMESTAMP
        )
        ''')
        
        # Tabela wiadomoÅ›ci
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS messages (
            id TEXT PRIMARY KEY,
            conversation_id TEXT,
            role TEXT,
            content TEXT,
            timestamp TIMESTAMP,
            attachments TEXT,
            FOREIGN KEY (conversation_id) REFERENCES conversations (id)
        )
        ''')
        
        self.conn.commit()

    def save_message(self, conversation_id: str, role: str, content: str, attachments=None) -> str:
        """Zapisz wiadomoÅ›Ä‡ w bazie danych"""
        cursor = self.conn.cursor()
        message_id = str(uuid.uuid4())
        
        # Przygotuj zaÅ‚Ä…czniki do zapisu (konwersja danych binarnych)
        serializable_attachments = []
        if attachments:
            for attachment in attachments:
                # Tworzymy nowy sÅ‚ownik zawierajÄ…cy tylko serializowalne dane
                serialized = {
                    "type": attachment.get("type", ""),
                    "name": attachment.get("name", "")
                }
                
                # JeÅ›li jest text_content, dodajemy go
                if "text_content" in attachment:
                    serialized["text_content"] = attachment["text_content"]
                
                # Nie zapisujemy binarnych danych w bazie danych
                serializable_attachments.append(serialized)
        
        attachments_json = json.dumps(serializable_attachments)
        
        cursor.execute(
            "INSERT INTO messages (id, conversation_id, role, content, timestamp, attachments) VALUES (?, ?, ?, ?, ?, ?)",
            (message_id, conversation_id, role, content, datetime.now(), attachments_json)
        )
        self.conn.commit()
        return message_id
    
    def get_messages(self, conversation_id: str) -> List[Dict[str, Any]]:
        """Pobierz wszystkie wiadomoÅ›ci dla konwersacji"""
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT role, content, attachments FROM messages WHERE conversation_id = ? ORDER BY timestamp",
            (conversation_id,)
        )
        
        messages = []
        for role, content, attachments_json in cursor.fetchall():
            try:
                attachments = json.loads(attachments_json) if attachments_json else []
                
                messages.append({
                    "role": role,
                    "content": content,
                    "attachments": attachments
                })
            except Exception as e:
                # W przypadku bÅ‚Ä™du, dodaj wiadomoÅ›Ä‡ bez zaÅ‚Ä…cznikÃ³w
                messages.append({
                    "role": role,
                    "content": content,
                    "attachments": []
                })
                
        return messages

    def get_messages_with_pagination(self, conversation_id: str, limit: int = None, offset: int = 0) -> List[Dict[str, Any]]:
        """Pobierz wiadomoÅ›ci dla konwersacji z paginacjÄ…"""
        cursor = self.conn.cursor()
        
        if limit is not None:
            cursor.execute(
                "SELECT role, content, attachments FROM messages WHERE conversation_id = ? ORDER BY timestamp LIMIT ? OFFSET ?",
                (conversation_id, limit, offset)
            )
        else:
            cursor.execute(
                "SELECT role, content, attachments FROM messages WHERE conversation_id = ? ORDER BY timestamp",
                (conversation_id,)
            )
        
        messages = []
        for role, content, attachments_json in cursor.fetchall():
            try:
                attachments = json.loads(attachments_json) if attachments_json else []
                
                messages.append({
                    "role": role,
                    "content": content,
                    "attachments": attachments
                })
            except Exception as e:
                print(f"BÅ‚Ä…d przetwarzania zaÅ‚Ä…cznika: {str(e)}")
                messages.append({
                    "role": role,
                    "content": content,
                    "attachments": []
                })
                
        return messages

    def get_message_count(self, conversation_id: str) -> int:
        """Pobierz liczbÄ™ wiadomoÅ›ci w konwersacji"""
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT COUNT(*) FROM messages WHERE conversation_id = ?",
            (conversation_id,)
        )
        return cursor.fetchone()[0]

    def save_conversation(self, conversation_id: str, title: str):
        """UtwÃ³rz lub zaktualizuj konwersacjÄ™"""
        cursor = self.conn.cursor()
        now = datetime.now()
        
        # SprawdÅº, czy konwersacja istnieje
        cursor.execute("SELECT id FROM conversations WHERE id = ?", (conversation_id,))
        if cursor.fetchone():
            # Aktualizuj istniejÄ…cÄ… konwersacjÄ™
            cursor.execute(
                "UPDATE conversations SET title = ?, updated_at = ? WHERE id = ?",
                (title, now, conversation_id)
            )
        else:
            # UtwÃ³rz nowÄ… konwersacjÄ™
            cursor.execute(
                "INSERT INTO conversations (id, title, created_at, updated_at) VALUES (?, ?, ?, ?)",
                (conversation_id, title, now, now)
            )
        
        self.conn.commit()
    
    def get_conversations(self) -> List[Dict[str, Any]]:
        """Pobierz wszystkie konwersacje"""
        cursor = self.conn.cursor()
        cursor.execute(
            "SELECT id, title, created_at FROM conversations ORDER BY updated_at DESC"
        )
        return [
            {"id": conv_id, "title": title, "created_at": created_at} 
            for conv_id, title, created_at in cursor.fetchall()
        ]

    def delete_conversation(self, conversation_id: str):
        """UsuÅ„ konwersacjÄ™ i jej wiadomoÅ›ci"""
        cursor = self.conn.cursor()
        # Najpierw usuÅ„ wiadomoÅ›ci (ograniczenie klucza obcego)
        cursor.execute("DELETE FROM messages WHERE conversation_id = ?", (conversation_id,))
        # UsuÅ„ konwersacjÄ™
        cursor.execute("DELETE FROM conversations WHERE id = ?", (conversation_id,))
        self.conn.commit()

# === Funkcje pomocnicze dla zarzÄ…dzania kontekstem i zaÅ‚Ä…cznikami ===
def prepare_messages_with_token_management(messages, system_prompt, model_id, llm_service):
    """Przygotowuje wiadomoÅ›ci do wysÅ‚ania, zarzÄ…dzajÄ…c limitami tokenÃ³w"""
    
    # Ustal limit tokenÃ³w dla rÃ³Å¼nych modeli
    model_token_limits = {
        "anthropic/claude-3.7-sonnet:floor": 180000,
        "anthropic/claude-3.7-sonnet:thinking": 180000,
        "anthropic/claude-3.5-haiku:floor": 150000,
        "openai/gpt-4o:floor": 120000, 
        "openai/gpt-4-turbo:floor": 100000,
    }
    
    # DomyÅ›lny limit, jeÅ›li model nie jest znany
    default_token_limit = 100000
    max_input_tokens = model_token_limits.get(model_id, default_token_limit)
    
    # Rezerwuj tokeny na odpowiedÅº i prompt systemowy
    max_completion_tokens = 12000
    system_tokens = llm_service.count_tokens(system_prompt) if system_prompt else 0
    available_tokens = max_input_tokens - system_tokens - max_completion_tokens - 100  # 100 jako bufor bezpieczeÅ„stwa
    
    # Przygotuj wiadomoÅ›ci API
    api_messages = []
    if system_prompt:
        api_messages.append({"role": "system", "content": system_prompt})
    
    # Policz tokeny aktualnych wiadomoÅ›ci
    current_tokens = 0
    user_messages = []
    assistant_messages = []
    
    # Najpierw zbierz wszystkie wiadomoÅ›ci
    for msg in messages:
        if msg["role"] == "user":
            user_messages.append(msg)
        else:
            assistant_messages.append(msg)
    
    # Zawsze doÅ‚Ä…cz ostatniÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika
    if user_messages:
        last_user_message = user_messages.pop()
    else:
        last_user_message = None
    
    # Zawsze doÅ‚Ä…cz ostatniÄ… odpowiedÅº asystenta, jeÅ›li istnieje
    if assistant_messages:
        last_assistant_message = assistant_messages.pop()
    else:
        last_assistant_message = None
    
    # Pierwsza wiadomoÅ›Ä‡ uÅ¼ytkownika jako kontekst, jeÅ›li istnieje
    if user_messages:
        first_user_message = user_messages.pop(0)
    else:
        first_user_message = None
    
    # Dodaj pierwszÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika do kontekstu
    if first_user_message:
        first_msg_tokens = llm_service.count_tokens(first_user_message["content"])
        if current_tokens + first_msg_tokens <= available_tokens:
            api_messages.append(first_user_message)
            current_tokens += first_msg_tokens
    
    # Proces dodawania pozostaÅ‚ych wiadomoÅ›ci w parach (zachowuje przepÅ‚yw konwersacji)
    remaining_messages = []
    # ÅÄ…czymy wiadomoÅ›ci z obu list naprzemiennie, zachowujÄ…c kolejnoÅ›Ä‡
    i, j = 0, 0
    while i < len(user_messages) or j < len(assistant_messages):
        if i < len(user_messages):
            remaining_messages.append(user_messages[i])
            i += 1
        if j < len(assistant_messages):
            remaining_messages.append(assistant_messages[j])
            j += 1
    
    # Sortuj pozostaÅ‚e wiadomoÅ›ci wedÅ‚ug czasu (najstarsze pierwsze)
    # ZakÅ‚adamy, Å¼e wiadomoÅ›ci sÄ… juÅ¼ uporzÄ…dkowane chronologicznie w bazie danych
    
    # Dodaj tyle wiadomoÅ›ci, ile zmieÅ›ci siÄ™ w limicie tokenÃ³w
    for msg in remaining_messages:
        msg_tokens = llm_service.count_tokens(msg["content"])
        
        # JeÅ›li wiadomoÅ›Ä‡ nie zmieÅ›ci siÄ™, przerwij
        if current_tokens + msg_tokens > available_tokens:
            break
        
        api_messages.append(msg)
        current_tokens += msg_tokens
    
    # Zawsze dodaj ostatniÄ… odpowiedÅº asystenta, jeÅ›li istnieje i jest miejsce
    if last_assistant_message:
        last_assistant_tokens = llm_service.count_tokens(last_assistant_message["content"])
        if current_tokens + last_assistant_tokens <= available_tokens:
            api_messages.append(last_assistant_message)
            current_tokens += last_assistant_tokens
        else:
            # JeÅ›li nie zmieÅ›ci siÄ™ caÅ‚a, dodaj skrÃ³conÄ… wersjÄ™
            truncated_content = "POPRZEDNIA ODPOWIEDÅ¹ (skrÃ³cona): " + last_assistant_message["content"][:1000] + "..."
            truncated_tokens = llm_service.count_tokens(truncated_content)
            if current_tokens + truncated_tokens <= available_tokens:
                api_messages.append({"role": "assistant", "content": truncated_content})
                current_tokens += truncated_tokens
    
    # Zawsze dodaj ostatniÄ… wiadomoÅ›Ä‡ uÅ¼ytkownika
    if last_user_message:
        last_user_tokens = llm_service.count_tokens(last_user_message["content"])
        
        # JeÅ›li ostatnia wiadomoÅ›Ä‡ uÅ¼ytkownika jest za dÅ‚uga, sprÃ³buj jÄ… skrÃ³ciÄ‡
        if current_tokens + last_user_tokens > available_tokens:
            # Oblicz, ile tokenÃ³w moÅ¼emy uÅ¼yÄ‡
            remaining_tokens = available_tokens - current_tokens
            
            # JeÅ›li za maÅ‚o miejsca, dodaj tylko treÅ›Ä‡ bez zaÅ‚Ä…cznikÃ³w
            if "attachments" in last_user_message and last_user_message["attachments"]:
                # WyodrÄ™bnij treÅ›Ä‡ bez zaÅ‚Ä…cznikÃ³w
                main_content = last_user_message["content"].split("\n\n[ZaÅ‚Ä…cznik")[0]
                main_content_tokens = llm_service.count_tokens(main_content)
                
                if main_content_tokens <= remaining_tokens:
                    # Dodaj tylko gÅ‚Ã³wnÄ… treÅ›Ä‡
                    modified_message = {"role": "user", "content": main_content}
                    api_messages.append(modified_message)
                else:
                    # SkrÃ³Ä‡ nawet gÅ‚Ã³wnÄ… treÅ›Ä‡, jeÅ›li potrzeba
                    truncated_content = main_content[:remaining_tokens * 4]  # PrzybliÅ¼enie
                    modified_message = {"role": "user", "content": truncated_content}
                    api_messages.append(modified_message)
            else:
                # SkrÃ³Ä‡ wiadomoÅ›Ä‡ uÅ¼ytkownika, jeÅ›li nie ma zaÅ‚Ä…cznikÃ³w
                truncated_content = last_user_message["content"][:remaining_tokens * 4]  # PrzybliÅ¼enie
                modified_message = {"role": "user", "content": truncated_content}
                api_messages.append(modified_message)
        else:
            # Dodaj peÅ‚nÄ… wiadomoÅ›Ä‡
            api_messages.append(last_user_message)
    
    return api_messages

def process_attachments(attachments):
    """Przetwarza zaÅ‚Ä…czniki w format odpowiedni do wysÅ‚ania do API"""
    processed_content = ""
    
    for attachment in attachments:
        att_type = attachment.get("type")
        att_name = attachment.get("name", "")
        
        if att_type == "file" and "text_content" in attachment:
            processed_content += f"\n\n[ZAÅÄ„CZNIK: {att_name}]\n{attachment['text_content']}\n"
        elif att_type == "image":
            processed_content += f"\n\n[OBRAZ: {att_name}]\n"
    
    return processed_content.strip()

def extract_image_content(image_file):
    """Konwertuje obraz na base64 dla modeli wspierajÄ…cych obrazy (np. GPT-4o)"""
    try:
        # Pobierz dane obrazu
        image_data = image_file.getvalue()
        
        # Konwertuj na base64
        base64_image = base64.b64encode(image_data).decode('utf-8')
        
        # OkreÅ›l typ MIME na podstawie rozszerzenia pliku
        mime_type = "image/jpeg"  # domyÅ›lny typ
        if isinstance(image_file, io.BytesIO):
            # ObsÅ‚uga dla BytesIO
            mime_type = "image/jpeg"  # DomyÅ›lnie zakÅ‚adamy JPEG
        else:
            # ObsÅ‚uga dla plikÃ³w z nazwÄ…
            try:
                file_name = image_file.name.lower()
                if file_name.endswith('.png'):
                    mime_type = "image/png"
                elif file_name.endswith(('.jpg', '.jpeg')):
                    mime_type = "image/jpeg"
            except:
                pass
        
        return {
            "base64_data": base64_image,
            "mime_type": mime_type
        }
    except Exception as e:
        print(f"BÅ‚Ä…d podczas przetwarzania obrazu: {str(e)}")
        return None

# === Serwis LLM ===
class LLMService:
    def __init__(self, api_key: str):
        self.api_key = api_key
        
        # Prosta pamiÄ™Ä‡ podrÄ™czna dla powtarzajÄ…cych siÄ™ pytaÅ„
        self.cache = {}

    def count_tokens(self, text: str) -> int:
        """Oszacuj liczbÄ™ tokenÃ³w dla Claude"""
        try:
            encoding = tiktoken.encoding_for_model("gpt-4")  # UÅ¼ywamy kodowania gpt-4 jako przybliÅ¼enia
            return len(encoding.encode(text))
        except:
            # Fallback do cl100k_base, jeÅ›li okreÅ›lone kodowanie nie jest dostÄ™pne
            try:
                encoding = tiktoken.get_encoding("cl100k_base")
                return len(encoding.encode(text))
            except Exception as e:
                # Ostateczny fallback - prymitywne oszacowanie
                return len(text) // 4  # Bardzo zgrubne przybliÅ¼enie: ~4 znaki na token

    def get_cache_key(self, messages, model, system_prompt, temperature):
        """Generuj klucz pamiÄ™ci podrÄ™cznej dla zapytania LLM"""
        cache_input = f"{json.dumps(messages)}-{model}-{system_prompt}-{temperature}"
        return hashlib.md5(cache_input.encode()).hexdigest()

    def call_llm(self, 
                messages: List[Dict[str, Any]], 
                model: str = "anthropic/claude-3.7-sonnet:floor", 
                system_prompt: str = None, 
                temperature: float = 0.7, 
                max_tokens: int = 12000,
                use_cache: bool = True) -> Dict[str, Any]:
        """WywoÅ‚aj API LLM przez OpenRouter z obsÅ‚ugÄ… obrazÃ³w i zaÅ‚Ä…cznikÃ³w"""
        # SprawdÅº pamiÄ™Ä‡ podrÄ™cznÄ…, jeÅ›li uÅ¼ywamy cachowania
        if use_cache and temperature < 0.1:  # Cachujemy tylko deterministyczne odpowiedzi
            cache_key = self.get_cache_key(messages, model, system_prompt, temperature)
            if cache_key in self.cache:
                return self.cache[cache_key]
        
        # Przygotuj wiadomoÅ›ci z promptem systemowym, jeÅ›li podano
        api_messages = []
        if system_prompt:
            api_messages.append({"role": "system", "content": system_prompt})
        
        # Przeanalizuj kaÅ¼dÄ… wiadomoÅ›Ä‡, szukajÄ…c obrazÃ³w do konwersji
        for msg in messages:
            message_content = msg.get("content", "")
            attachments = msg.get("attachments", [])
            
            # ObsÅ‚uga obrazÃ³w dla modeli, ktÃ³re je wspierajÄ… (jak GPT-4o)
            if msg.get("role") == "user" and "attachments" in msg and any(att.get("type") == "image" for att in attachments):
                # Przygotuj format dla obrazÃ³w, jeÅ›li uÅ¼ywamy modeli obsÅ‚ugujÄ…cych obrazy
                if model in ["openai/gpt-4o:floor", "openai/gpt-4-vision"]:
                    content_parts = [{"type": "text", "text": message_content}]
                    
                    for attachment in attachments:
                        if attachment.get("type") == "image" and attachment.get("image_data"):
                            content_parts.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{attachment.get('mime_type', 'image/jpeg')};base64,{attachment['image_data']['base64_data']}",
                                }
                            })
                    
                    api_messages.append({"role": msg["role"], "content": content_parts})
                else:
                    # Dla modeli bez wsparcia obrazÃ³w, dodaj tylko tekst z opisem zaÅ‚Ä…cznikÃ³w
                    api_messages.append({"role": msg["role"], "content": message_content})
            else:
                # ZwykÅ‚a wiadomoÅ›Ä‡ tekstowa
                api_messages.append({"role": msg["role"], "content": message_content})
        
        # Oblicz tokeny promptu
        prompt_text = system_prompt or ""
        for msg in messages:
            if isinstance(msg.get("content"), str):
                prompt_text += msg["content"]
            elif isinstance(msg.get("content"), list):  # Dla wiadomoÅ›ci multimodalnych (GPT-4o)
                for part in msg["content"]:
                    if part.get("type") == "text":
                        prompt_text += part.get("text", "")
        
        prompt_tokens = self.count_tokens(prompt_text)
        
        # Zdefiniuj parametry ponawiania
        max_retries = 3
        retry_delay = 2  # sekundy
        
        # PrÃ³ba wywoÅ‚ania API z ponawianiem
        for attempt in range(max_retries):
            try:
                api_payload = {
                    "model": model,
                    "messages": api_messages,
                    "temperature": temperature,
                    "max_tokens": max_tokens
                }
                
                response = requests.post(
                    "https://openrouter.ai/api/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    },
                    json=api_payload,
                    timeout=180  # ZwiÄ™kszenie timeout do 3 minut
                )
                response.raise_for_status()
                result = response.json()
                
                # Oszacuj tokeny odpowiedzi
                response_content = result["choices"][0]["message"]["content"]
                completion_tokens = self.count_tokens(response_content)
                
                # Dodaj informacje o tokenach do wyniku
                result["usage"] = {
                    "prompt_tokens": prompt_tokens,
                    "completion_tokens": completion_tokens,
                    "total_tokens": prompt_tokens + completion_tokens
                }
                
                # Dodaj do pamiÄ™ci podrÄ™cznej, jeÅ›li uÅ¼ywamy cachowania
                if use_cache and temperature < 0.1:
                    cache_key = self.get_cache_key(messages, model, system_prompt, temperature)
                    self.cache[cache_key] = result
                
                return result
            
            except requests.exceptions.RequestException as e:
                if attempt == max_retries - 1:  # Ostatnia prÃ³ba
                    raise Exception(f"Nie udaÅ‚o siÄ™ poÅ‚Ä…czyÄ‡ z API po {max_retries} prÃ³bach: {str(e)}")
                
                # Czekaj przed ponowieniem
                time.sleep(retry_delay * (2 ** attempt))  # WykÅ‚adnicze wycofanie

# === Funkcje pomocnicze ===
def calculate_cost(model_id: str, prompt_tokens: int, completion_tokens: int) -> float:
    """Oblicz szacowany koszt zapytania w USD"""
    for model in MODEL_OPTIONS:
        if model["id"] == model_id:
            return (prompt_tokens / 1_000_000) * model["pricing"]["prompt"] + \
                   (completion_tokens / 1_000_000) * model["pricing"]["completion"]
    return 0.0  # W przypadku nieznalezienia modelu

def format_message_for_display(message: Dict[str, str]) -> str:
    """Formatuj wiadomoÅ›Ä‡ do wyÅ›wietlenia w interfejsie, ze wsparciem dla blokÃ³w kodu"""
    content = message.get("content", "")
    
    # WyodrÄ™bnianie i formatowanie blokÃ³w kodu
    def replace_code_block(match):
        lang = match.group(1) or ""
        code = match.group(2)
        return f"```{lang}\n{code}\n```"
    
    # ZastÄ…p bloki kodu ze skÅ‚adniÄ… markdown
    content = re.sub(r"```(.*?)\n(.*?)```", replace_code_block, content, flags=re.DOTALL)
    
    return content

def get_conversation_title(messages: List[Dict[str, str]], llm_service: LLMService, api_key: str) -> str:
    """Wygeneruj tytuÅ‚ dla nowej konwersacji na podstawie pierwszej wiadomoÅ›ci uÅ¼ytkownika"""
    if not messages:
        return f"Nowa konwersacja {datetime.now().strftime('%d-%m-%Y %H:%M')}"
    
    # UÅ¼yj pierwszej wiadomoÅ›ci uÅ¼ytkownika jako podstawy tytuÅ‚u
    user_message = next((m["content"] for m in messages if m["role"] == "user"), "")
    
    if len(user_message) > 40:
        # Skorzystaj z LLM, aby stworzyÄ‡ krÃ³tki, opisowy tytuÅ‚
        try:
            response = llm_service.call_llm(
                messages=[
                    {"role": "user", "content": f"UtwÃ³rz krÃ³tki, opisowy tytuÅ‚ (max. 5 sÅ‚Ã³w) dla nastÄ™pujÄ…cej konwersacji, bez cudzysÅ‚owÃ³w: {user_message[:200]}..."}
                ],
                model="anthropic/claude-3.5-haiku:floor",  # TaÅ„szy model jest wystarczajÄ…cy do tworzenia tytuÅ‚Ã³w
                system_prompt="JesteÅ› pomocnym asystentem, ktÃ³ry tworzy krÃ³tkie, opisowe tytuÅ‚y konwersacji.",
                temperature=0.2,
                max_tokens=20,
                use_cache=True
            )
            title = response["choices"][0]["message"]["content"].strip().strip('"\'')
            # UsuÅ„ znaki, ktÃ³re mogÅ‚yby sprawiaÄ‡ problemy z interfejsem
            title = re.sub(r'[^\w\s\-.,]', '', title)
            return title[:40]
        except Exception:
            # W przypadku bÅ‚Ä™du, wrÃ³Ä‡ do domyÅ›lnego tytuÅ‚u
            pass
    
    # DomyÅ›lnie uÅ¼yj skrÃ³conej wiadomoÅ›ci uÅ¼ytkownika
    return user_message[:40] + ("..." if len(user_message) > 40 else "")

# === Komponenty interfejsu uÅ¼ytkownika ===
def sidebar_component():
    """Komponent paska bocznego z konwersacjami i ustawieniami"""
    st.sidebar.title("AI Asystent Developera")
    
    # Ustawienia modelu
    with st.sidebar.expander("âš™ï¸ Ustawienia modelu", expanded=False):
        model_options = {model["id"]: f"{model['name']}" for model in MODEL_OPTIONS}
        selected_model = st.selectbox(
            "Model LLM",
            options=list(model_options.keys()),
            format_func=lambda x: model_options[x],
            index=0,
            key="model_selection"
        )
        
        # PokaÅ¼ opis modelu
        for model in MODEL_OPTIONS:
            if model["id"] == selected_model:
                st.info(model["description"])
        
        temperature = st.slider(
            "Temperatura",
            min_value=0.0,
            max_value=1.0,
            value=st.session_state.get("temperature", 0.7),
            step=0.1,
            help="WyÅ¼sza wartoÅ›Ä‡ = bardziej kreatywne odpowiedzi"
        )
        
        st.session_state["temperature"] = temperature
        
        custom_system_prompt = st.text_area(
            "Prompt systemowy (opcjonalnie)",
            value=st.session_state.get("custom_system_prompt", DEFAULT_SYSTEM_PROMPT),
            help="Dostosuj zachowanie asystenta"
        )
        
        if st.button("Zresetuj do domyÅ›lnego"):
            custom_system_prompt = DEFAULT_SYSTEM_PROMPT
        
        st.session_state["custom_system_prompt"] = custom_system_prompt
    
    # Statystyki tokenÃ³w
    if "token_usage" in st.session_state:
        with st.sidebar.expander("ğŸ“Š Statystyki tokenÃ³w", expanded=False):
            st.metric("Tokeny prompt", st.session_state["token_usage"]["prompt"])
            st.metric("Tokeny completion", st.session_state["token_usage"]["completion"])
            st.metric("Szacunkowy koszt", f"${st.session_state['token_usage']['cost']:.4f}")
    
    # Lista konwersacji
    db = st.session_state.get("db")
    if db:
        with st.sidebar.expander("ğŸ’¬ Konwersacje", expanded=True):
            conversations = db.get_conversations()
            
            if conversations:
                for conv in conversations:
                    col1, col2 = st.columns([4, 1])
                    with col1:
                        if st.button(conv["title"], key=f"conv_{conv['id']}", use_container_width=True):
                            st.session_state["current_conversation_id"] = conv["id"]
                            st.rerun()
                    with col2:
                        if st.button("ğŸ—‘ï¸", key=f"del_{conv['id']}", help="UsuÅ„ konwersacjÄ™"):
                            db.delete_conversation(conv["id"])
                            if st.session_state.get("current_conversation_id") == conv["id"]:
                                st.session_state["current_conversation_id"] = None
                            st.rerun()
            else:
                st.write("Brak zapisanych konwersacji")
        
        # Przycisk nowej konwersacji
        if st.sidebar.button("â• Nowa konwersacja", use_container_width=True):
            st.session_state["current_conversation_id"] = str(uuid.uuid4())
            # WyczyÅ›Ä‡ zaÅ‚Ä…czniki dla nowej konwersacji
            st.session_state["attachments"] = []
            st.session_state["attached_images"] = {}
            st.rerun()

@requires_auth
def chat_component():
    """Komponent interfejsu czatu"""
    # Dodaj niestandardowy CSS dla przypiÄ™tego paska wejÅ›ciowego
    st.markdown("""
    <style>
    /* Miejsce na pasek wejÅ›ciowy na dole */
    .main .block-container {
        padding-bottom: 80px;
    }
    
    /* Przytwierdzony pasek wejÅ›ciowy na dole ekranu */
    .stChatInputContainer {
        position: fixed;
        bottom: 0;
        left: 240px; /* Miejsce na sidebar */
        right: 0;
        padding: 1rem;
        background: white;
        z-index: 999;
        border-top: 1px solid #ddd;
    }
    
    /* Stylowanie zaÅ‚Ä…cznikÃ³w */
    .attachment-badge {
        display: inline-block;
        padding: 2px 8px;
        margin: 2px;
        background-color: #f0f2f6;
        border-radius: 10px;
        font-size: 0.8em;
    }
    
    /* Style dla blokÃ³w kodu */
    .stMarkdown pre {
        overflow-x: auto;
    }
    
    /* Na urzÄ…dzeniach mobilnych */
    @media (max-width: 768px) {
        .stChatInputContainer {
            left: 0;
        }
    }
    </style>
    """, unsafe_allow_html=True)
    
    # Pobierz klucz API z secrets
    api_key = st.secrets.get("OPENROUTER_API_KEY", "")
    if not api_key:
        st.warning("âš ï¸ Brak klucza API OpenRouter w ustawieniach secrets.")
        return

    # Aktualizuj klucz API w sesji
    st.session_state["api_key"] = api_key

    # Pobierz instancjÄ™ serwisu LLM i bazy danych
    if "llm_service" not in st.session_state or st.session_state.get("llm_service") is None:
        st.session_state["llm_service"] = LLMService(api_key)

    llm_service = st.session_state.get("llm_service")
    db = st.session_state.get("db")

    if not llm_service or not db:
        st.error("âš ï¸ Nie moÅ¼na zainicjalizowaÄ‡ serwisÃ³w. OdÅ›wieÅ¼ stronÄ™ i sprÃ³buj ponownie.")
        return

    # Inicjalizacja zmiennych sesji dla konwersacji
    if "current_conversation_id" not in st.session_state:
        st.session_state["current_conversation_id"] = str(uuid.uuid4())

    current_conversation_id = st.session_state["current_conversation_id"]

    # Statystyki konwersacji
    if "token_usage" not in st.session_state:
        st.session_state["token_usage"] = {"prompt": 0, "completion": 0, "cost": 0.0}
    
    # Inicjalizacja zmiennych dla zaÅ‚Ä…cznikÃ³w
    if "attachments" not in st.session_state:
        st.session_state["attachments"] = []

    if "attached_images" not in st.session_state:
        st.session_state["attached_images"] = {}

    # Pobierz wiadomoÅ›ci
    messages = db.get_messages(current_conversation_id)
    
    # WyÅ›wietl istniejÄ…ce wiadomoÅ›ci
    for message in messages:
        role = message["role"]
        content = format_message_for_display(message)

        if role == "user":
            with st.chat_message("user"):
                st.markdown(content)
                # WyÅ›wietl zaÅ‚Ä…czniki jeÅ›li istniejÄ… - tylko obrazy
                for attachment in message.get("attachments", []):
                    if attachment.get("type") == "image":
                        try:
                            # ZaÅ‚Ä…czniki obrazÃ³w sÄ… trzymane w sesji, a nie w DB
                            if "attached_images" in st.session_state and attachment.get("name") in st.session_state["attached_images"]:
                                img_data = st.session_state["attached_images"][attachment.get("name")]
                                st.image(img_data, caption=attachment.get("name", "ZaÅ‚Ä…cznik"))
                        except Exception as e:
                            st.warning(f"Nie moÅ¼na wyÅ›wietliÄ‡ obrazu: {attachment.get('name')}")

        elif role == "assistant":
            with st.chat_message("assistant"):
                st.markdown(content)

    # WyÅ›wietlanie zaÅ‚Ä…cznikÃ³w (jako tekst pod polem wejÅ›ciowym)
    if st.session_state["attachments"]:
        attachment_text = "ZaÅ‚Ä…czniki: " + " ".join([
            f"<span class='attachment-badge'>{attachment.get('type')} | {attachment.get('name')[:15]}...</span>"
            for attachment in st.session_state["attachments"]
        ])
        st.markdown(f"<div style='margin-bottom: 5px'>{attachment_text}</div>", unsafe_allow_html=True)
    
    # ObsÅ‚uga zaÅ‚Ä…cznikÃ³w - tylko ikony pod polem czatu
    col1, col2, col3 = st.columns([1, 1, 1])
    
    with col1:
        if st.button("ğŸ“· Obraz", use_container_width=True):
            st.session_state["show_image_uploader"] = not st.session_state.get("show_image_uploader", False)
            st.rerun()
    
    with col2:
        if st.button("ğŸ“„ Plik", use_container_width=True):
            st.session_state["show_file_uploader"] = not st.session_state.get("show_file_uploader", False)
            st.rerun()
    
    with col3:
        if st.button("ğŸ’» Kod", use_container_width=True):
            st.session_state["show_code_input"] = not st.session_state.get("show_code_input", False)
            st.rerun()
    
    # ZarzÄ…dzanie istniejÄ…cymi zaÅ‚Ä…cznikami
    if st.session_state["attachments"]:
        cols = st.columns(len(st.session_state["attachments"]))
        for i, (col, attachment) in enumerate(zip(cols, st.session_state["attachments"])):
            with col:
                if st.button(f"âŒ {attachment.get('name', '')[:7]}...", key=f"del_{i}"):
                    if attachment.get("type") == "image" and attachment.get("name") in st.session_state["attached_images"]:
                        del st.session_state["attached_images"][attachment.get("name")]
                    st.session_state["attachments"].pop(i)
                    st.rerun()

    # Formularze zaÅ‚Ä…cznikÃ³w
    if st.session_state.get("show_image_uploader", False):
        with st.expander("Dodaj obraz", expanded=True):
            uploaded_file = st.file_uploader("Wybierz obraz", type=["png", "jpg", "jpeg"], key="image_upload")
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("Anuluj", use_container_width=True):
                    st.session_state["show_image_uploader"] = False
                    st.rerun()
            with col2:
                if uploaded_file is not None and st.button("Dodaj", use_container_width=True):
                    image_name = uploaded_file.name
                    st.session_state["attached_images"][image_name] = uploaded_file.getvalue()
                    st.session_state["attachments"].append({
                        "type": "image",
                        "name": image_name
                    })
                    st.session_state["show_image_uploader"] = False
                    st.success(f"Dodano obraz: {image_name}")
                    st.rerun()

    if st.session_state.get("show_file_uploader", False):
        with st.expander("Dodaj plik tekstowy", expanded=True):
            uploaded_file = st.file_uploader("Wybierz plik", type=["txt", "md", "json", "csv"], key="text_upload")
            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("Anuluj", use_container_width=True):
                    st.session_state["show_file_uploader"] = False
                    st.rerun()
            with col2:
                if uploaded_file is not None and st.button("Dodaj", use_container_width=True):
                    try:
                        text_content = uploaded_file.getvalue().decode("utf-8")
                        st.session_state["attachments"].append({
                            "type": "file",
                            "name": uploaded_file.name,
                            "text_content": text_content
                        })
                        st.session_state["show_file_uploader"] = False
                        st.success(f"Dodano plik: {uploaded_file.name}")
                        st.rerun()
                    except Exception as e:
                        st.error(f"BÅ‚Ä…d odczytu pliku: {str(e)}")

    if st.session_state.get("show_code_input", False):
        with st.expander("Dodaj kod", expanded=True):
            code_language = st.selectbox("JÄ™zyk programowania", 
                                         ["python", "javascript", "html", "css", "json", "sql", "bash"], 
                                         key="code_language")
            code_content = st.text_area("Wklej kod", height=150, key="code_content")
            file_name = st.text_input("Nazwa pliku (opcjonalnie)", 
                                      value=f"code.{code_language}", 
                                      key="code_filename")

            col1, col2 = st.columns([1, 1])
            with col1:
                if st.button("Anuluj", use_container_width=True):
                    st.session_state["show_code_input"] = False
                    st.rerun()
            with col2:
                if code_content and st.button("Dodaj", use_container_width=True):
                    st.session_state["attachments"].append({
                        "type": "file",
                        "name": file_name,
                        "text_content": f"```{code_language}\n{code_content}\n```"
                    })
                    st.session_state["show_code_input"] = False
                    st.success(f"Dodano kod: {file_name}")
                    st.rerun()
    
    # Pole wejÅ›ciowe uÅ¼ytkownika - ostatni element
    user_input = st.chat_input("Wpisz swoje pytanie lub zadanie...")

    # ObsÅ‚uga wprowadzonego komunikatu
    if user_input:
        # Natychmiast wyÅ›wietl wiadomoÅ›Ä‡ uÅ¼ytkownika
        with st.chat_message("user"):
            st.markdown(user_input)
            # PokaÅ¼ zaÅ‚Ä…czniki obrazÃ³w
            for attachment in st.session_state.get("attachments", []):
                if attachment.get("type") == "image":
                    try:
                        if "attached_images" in st.session_state and attachment.get("name") in st.session_state["attached_images"]:
                            img_data = st.session_state["attached_images"][attachment.get("name")]
                            st.image(img_data, caption=attachment.get("name", "ZaÅ‚Ä…cznik"))
                    except Exception as e:
                        st.error(f"BÅ‚Ä…d wyÅ›wietlania obrazu: {str(e)}")
        
        # Przygotuj treÅ›Ä‡ wiadomoÅ›ci i zaÅ‚Ä…czniki
        message_content = user_input
        
        # PrzetwÃ³rz zaÅ‚Ä…czniki
        attachments_to_send = []
        for attachment in st.session_state.get("attachments", []):
            attachment_copy = attachment.copy()
            
            # Dodaj dane obrazu dla modeli obsÅ‚ugujÄ…cych obrazy
            if attachment.get("type") == "image" and attachment.get("name") in st.session_state["attached_images"]:
                img_data = st.session_state["attached_images"][attachment.get("name")]
                image_content = extract_image_content(io.BytesIO(img_data))
                if image_content:
                    attachment_copy["image_data"] = image_content
                    
            attachments_to_send.append(attachment_copy)
        
        # Dodaj informacje o zaÅ‚Ä…cznikach do treÅ›ci wiadomoÅ›ci
        attachments_text = process_attachments(attachments_to_send)
        if attachments_text:
            message_content += "\n\n" + attachments_text
        
        # SprawdÅº, czy konwersacja ma tytuÅ‚
        if len(messages) == 0:
            conversation_title = get_conversation_title([{"role": "user", "content": user_input}], llm_service, st.session_state["api_key"])
            db.save_conversation(current_conversation_id, conversation_title)
        
        # Zapisz wiadomoÅ›Ä‡ uÅ¼ytkownika w bazie danych
        db.save_message(current_conversation_id, "user", user_input, attachments_to_send)
        
        # Pobierz wszystkie wiadomoÅ›ci, aby zachowaÄ‡ kontekst
        all_messages = db.get_messages(current_conversation_id)
        
        # WyÅ›wietl oczekujÄ…cÄ… odpowiedÅº asystenta
        with st.chat_message("assistant"):
            with st.spinner("Generowanie odpowiedzi..."):
                try:
                    model = st.session_state.get("model_selection", MODEL_OPTIONS[0]["id"])
                    system_prompt = st.session_state.get("custom_system_prompt", DEFAULT_SYSTEM_PROMPT)
                    temperature = st.session_state.get("temperature", 0.7)
                    
                    # UÅ¼yj funkcji optymalizujÄ…cej kontekst
                    optimized_messages = prepare_messages_with_token_management(
                        all_messages, 
                        system_prompt, 
                        model, 
                        llm_service
                    )
                    
                    response = llm_service.call_llm(
                        messages=optimized_messages,
                        model=model,
                        system_prompt=None,  # System prompt jest juÅ¼ dodany w optimized_messages
                        temperature=temperature,
                        max_tokens=12000
                    )
                    
                    assistant_response = response["choices"][0]["message"]["content"]
                    
                    # Aktualizuj statystyki tokenÃ³w
                    if "usage" in response:
                        usage = response["usage"]
                        st.session_state["token_usage"]["prompt"] += usage["prompt_tokens"]
                        st.session_state["token_usage"]["completion"] += usage["completion_tokens"]
                        
                        # Oblicz koszt
                        cost = calculate_cost(
                            model, 
                            usage["prompt_tokens"], 
                            usage["completion_tokens"]
                        )
                        
                        st.session_state["token_usage"]["cost"] += cost
                    
                    # Zapisz odpowiedÅº asystenta
                    db.save_message(current_conversation_id, "assistant", assistant_response)
                    
                    # WyÅ›wietl odpowiedÅº
                    st.markdown(assistant_response)
                    
                    # WyczyÅ›Ä‡ zaÅ‚Ä…czniki po wysÅ‚aniu
                    st.session_state["attachments"] = []
                    # Ukryj formularze zaÅ‚Ä…cznikÃ³w
                    st.session_state["show_image_uploader"] = False
                    st.session_state["show_file_uploader"] = False  
                    st.session_state["show_code_input"] = False
                    
                    # OdÅ›wieÅ¼ stronÄ™ aby wyÅ›wietliÄ‡ nowÄ… wiadomoÅ›Ä‡ bez spinnerÃ³w
                    st.rerun()
                    
                except Exception as e:
                    st.error(f"WystÄ…piÅ‚ bÅ‚Ä…d: {str(e)}")
                    st.code(traceback.format_exc())

# === GÅ‚Ã³wna aplikacja ===
def main():
    st.set_page_config(
        page_title="AI Asystent Developera Streamlit",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # Inicjalizacja serwisÃ³w
    if "db" not in st.session_state:
        st.session_state["db"] = AssistantDB()
    
    # SprawdÅº autentykacjÄ™
    if not st.session_state.get("authenticated", False):
        login_page()
        return
    
    # Pobierz klucz API z secrets
    api_key = st.secrets.get("OPENROUTER_API_KEY", "")
    if api_key and "llm_service" not in st.session_state:
        st.session_state["llm_service"] = LLMService(api_key)
        st.session_state["api_key"] = api_key
    
    # WyÅ›wietl sidebar
    sidebar_component()
    
    # WyÅ›wietl gÅ‚Ã³wny komponent czatu
    chat_component()

if __name__ == "__main__":
    main()
